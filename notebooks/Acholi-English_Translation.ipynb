{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Acholi - English Translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "99454cde1ee74a458cd593323aaf7fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7ce1a80f7d5e4cfd819ea5ec3dd1896d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_94b456ddca53435089bb30af2b6eb5ae",
              "IPY_MODEL_ae9ee7781d0044bfb4e8691e3ee02cf2"
            ]
          }
        },
        "7ce1a80f7d5e4cfd819ea5ec3dd1896d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94b456ddca53435089bb30af2b6eb5ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8b4dce032c374ce2a4501fb9d3377ed0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_77d58f9f091a41ab90ebfb972999e62c"
          }
        },
        "ae9ee7781d0044bfb4e8691e3ee02cf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_16d112a0d2e14f1b87a379c219c44545",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.13k/1.13k [00:00&lt;00:00, 38.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95ce872a07bb48f3bd79b9058a37694c"
          }
        },
        "8b4dce032c374ce2a4501fb9d3377ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "77d58f9f091a41ab90ebfb972999e62c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16d112a0d2e14f1b87a379c219c44545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95ce872a07bb48f3bd79b9058a37694c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25d1b72e561f4f6da6d9590ec6a7379a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_50766cfbb15043da9f7f0a47d3bee3c7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9a52994d7e624ce99ceb5f36239d3876",
              "IPY_MODEL_e4abcdd737e6489083631bfa1405edb7"
            ]
          }
        },
        "50766cfbb15043da9f7f0a47d3bee3c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a52994d7e624ce99ceb5f36239d3876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_52a40e997bde4e3ba874c05d60c44163",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 769849,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 769849,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c46b210e4524262adbdea7f4e7e9900"
          }
        },
        "e4abcdd737e6489083631bfa1405edb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_040045e2a7e440e4814e5cb6a56dc357",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 770k/770k [00:02&lt;00:00, 376kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fa6ca43c7044579b56273f78e369cbd"
          }
        },
        "52a40e997bde4e3ba874c05d60c44163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c46b210e4524262adbdea7f4e7e9900": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "040045e2a7e440e4814e5cb6a56dc357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8fa6ca43c7044579b56273f78e369cbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9370d3c5529e4f28897a1f07de5b270d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_640b89333dd54218a35314ad45228ba6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_03edef6abf534e8e8e59b5319db8d350",
              "IPY_MODEL_3b3ae8b58e154da290223b5d24989a2c"
            ]
          }
        },
        "640b89333dd54218a35314ad45228ba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03edef6abf534e8e8e59b5319db8d350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9d8f963247a84ef2b90caa6fffe04523",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 741813,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 741813,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c5c5dbe24194268bfa702963584220e"
          }
        },
        "3b3ae8b58e154da290223b5d24989a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_552385d83c1e4e379e4e3fbc07146f34",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 742k/742k [01:34&lt;00:00, 7.86kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_abddaefefea941aaba0e154e90111ad7"
          }
        },
        "9d8f963247a84ef2b90caa6fffe04523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c5c5dbe24194268bfa702963584220e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "552385d83c1e4e379e4e3fbc07146f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "abddaefefea941aaba0e154e90111ad7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b169deffab94d9da3be24a5424d4710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c49b46ebbd64411fa2e86ed2de280b64",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aa768c14e136423482b575e4d9a1e2ed",
              "IPY_MODEL_830906cddbc94b98a6e29daf45f71cbd"
            ]
          }
        },
        "c49b46ebbd64411fa2e86ed2de280b64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa768c14e136423482b575e4d9a1e2ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b390a1559657441fa3a610db1b37bedf",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1108211,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1108211,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_44993f48629643a399c8760cd2b72ea9"
          }
        },
        "830906cddbc94b98a6e29daf45f71cbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4929ceee0f3440db9333f50935b8de47",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.11M/1.11M [00:55&lt;00:00, 19.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a3dfd26daa7c41d3b81b86ca2b9e06f7"
          }
        },
        "b390a1559657441fa3a610db1b37bedf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "44993f48629643a399c8760cd2b72ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4929ceee0f3440db9333f50935b8de47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a3dfd26daa7c41d3b81b86ca2b9e06f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "433f1e436c5c469a948ddc83fc74ce82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_49cfab546c2f4f20a44f5c09966b196e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_afd1df97667f43b78dd75ccc538f8558",
              "IPY_MODEL_f1f5bc8efc3e44cebf9a2c52e9bbdc91"
            ]
          }
        },
        "49cfab546c2f4f20a44f5c09966b196e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "afd1df97667f43b78dd75ccc538f8558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_febbaca7cf504b8083ab99f3e5ab94ab",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 43,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 43,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9425a1a614b246f68e63478c8e78a4ef"
          }
        },
        "f1f5bc8efc3e44cebf9a2c52e9bbdc91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c783675a27ce40a09e504e94487a41e2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 43.0/43.0 [00:53&lt;00:00, 1.25s/B]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a32ffb95156a486aa03b34ee1dd66c19"
          }
        },
        "febbaca7cf504b8083ab99f3e5ab94ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9425a1a614b246f68e63478c8e78a4ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c783675a27ce40a09e504e94487a41e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a32ffb95156a486aa03b34ee1dd66c19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23ac4abba34f4b1b89892354c4570c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7d9476d9f48c4d56be384ba2c1dcf2bd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_76d6e1944fb54941a23454611484a2ac",
              "IPY_MODEL_ba978dbdbd89436ca0be9e6f30d9bb18"
            ]
          }
        },
        "7d9476d9f48c4d56be384ba2c1dcf2bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76d6e1944fb54941a23454611484a2ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0e9f77d038da4db182892a473748ac8b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 285893229,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 285893229,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6962e7a72ae400c81f9994a7c670eae"
          }
        },
        "ba978dbdbd89436ca0be9e6f30d9bb18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0cfd512fd938467eb831558221afac2a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 286M/286M [00:29&lt;00:00, 9.78MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7f43c66403142a0a75d35927259b8fd"
          }
        },
        "0e9f77d038da4db182892a473748ac8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6962e7a72ae400c81f9994a7c670eae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0cfd512fd938467eb831558221afac2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7f43c66403142a0a75d35927259b8fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZSTzxoJY7Qo",
        "outputId": "4828481d-98fe-4c9b-fb9b-e91cf4401cfb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZTW2y-jDvkp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b52b96-a19e-4cb9-97c7-2bc2764be5a0"
      },
      "source": [
        "!pip install --no-cache-dir transformers sentencepiece\n",
        "#installing the hugging face library"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 5.5MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 15.7MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 27.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 36.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=f3d05d16bc2e30ed8b1ee71a7e889710875163c4b3c62130c980cf752f12858f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vcdijvod/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers, sentencepiece\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.4 transformers-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u94DKH_uEDvz"
      },
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbuZwtAUhkq0"
      },
      "source": [
        "\n",
        "#Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGh1hmYOF-r3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15fe980e-77b6-47bd-a200-48eb6157174f"
      },
      "source": [
        "!pip install opustools-pkg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opustools-pkg\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/9f/e829a0cceccc603450cd18e1ff80807b6237a88d9a8df2c0bb320796e900/opustools_pkg-0.0.52-py3-none-any.whl (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 26.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 20kB 17.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 40kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 61kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 71kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 6.3MB/s \n",
            "\u001b[?25hInstalling collected packages: opustools-pkg\n",
            "Successfully installed opustools-pkg-0.0.52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlC7kWGARrqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c534fc35-2aa3-469e-8cd8-f8e6432dd9f9"
      },
      "source": [
        "! opus_read -d JW300 -s ach -t en -wm moses -w jw300.ach jw300.en -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Alignment file /proj/nlpl/data/OPUS/JW300/latest/xml/ach-en.xml.gz not found. The following files are available for downloading:\n",
            "\n",
            " 724 KB https://object.pouta.csc.fi/OPUS-JW300/v1/xml/ach-en.xml.gz\n",
            "   8 MB https://object.pouta.csc.fi/OPUS-JW300/v1/xml/ach.zip\n",
            " 263 MB https://object.pouta.csc.fi/OPUS-JW300/v1/xml/en.zip\n",
            "\n",
            " 272 MB Total size\n",
            "Unable to retrieve the data.\n",
            "No alignment file \"/proj/nlpl/data/OPUS/JW300/latest/xml/ach-en.xml.gz\" or \"./JW300_latest_xml_ach-en.xml.gz\" found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5AkLNY9We7h"
      },
      "source": [
        "#change these variables to train a model on a different set of languages\n",
        "source_language=\"ach\"\n",
        "target_language=\"en\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO6Ore9fVuaJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "d97e803f-217e-4eef-b0a6-9b523c82649e"
      },
      "source": [
        "# TMX file to dataframe\n",
        "source_file = 'jw300.' + source_language\n",
        "target_file = 'jw300.' + target_language\n",
        "\n",
        "source = []\n",
        "target = []\n",
        "skip_lines = []  # Collect the line numbers of the source portion to skip the same lines for the target portion.\n",
        "with open(source_file) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        # Skip sentences that are contained in the test set.\n",
        "            source.append(line.strip())\n",
        "                     \n",
        "with open(target_file) as f:\n",
        "    for j, line in enumerate(f):\n",
        "        # Only add to corpus if corresponding source was not skipped.\n",
        "            target.append(line.strip())\n",
        "       \n",
        "df = pd.DataFrame(zip(source, target), columns=['source_sentence', 'target_sentence'])\n",
        "# if you get TypeError: data argument can't be an iterator is because of your zip version run this below\n",
        "#df = pd.DataFrame(list(zip(source, target)), columns=['source_sentence', 'target_sentence'])\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_sentence</th>\n",
              "      <th>target_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lok ma Tye i Iye</td>\n",
              "      <td>Table of Contents</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Marci 1 , 2011</td>\n",
              "      <td>March 1 , 2011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>“ Kwena Maber me Ker ” Obedo Gin Ango ?</td>\n",
              "      <td>The “ Good News of the Kingdom ” ​ — What Is It ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PWONY MA KWAKO LOK MA I POK NGEYE</td>\n",
              "      <td>FROM OUR COVER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3 Lok Mo ma Pire Tek pa Lanebi</td>\n",
              "      <td>3 A Prophecy of Enormous Importance</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           source_sentence                                    target_sentence\n",
              "0                         Lok ma Tye i Iye                                  Table of Contents\n",
              "1                           Marci 1 , 2011                                     March 1 , 2011\n",
              "2  “ Kwena Maber me Ker ” Obedo Gin Ango ?  The “ Good News of the Kingdom ” ​ — What Is It ?\n",
              "3        PWONY MA KWAKO LOK MA I POK NGEYE                                     FROM OUR COVER\n",
              "4           3 Lok Mo ma Pire Tek pa Lanebi                3 A Prophecy of Enormous Importance"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S4QGJFZgyeS"
      },
      "source": [
        "##Data Preprocessing and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeSMYszqouYX"
      },
      "source": [
        "seed=23"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gclF4NdCpI0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c51d1d3-5147-40c8-897a-bf776e21762e"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81969"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq_EjXprcodg"
      },
      "source": [
        "df.replace('', np.nan, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaOSIl2KdCIk"
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebNDHDFnkZd1"
      },
      "source": [
        "df=df.applymap(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtcXBRknqFnp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "956d7663-7fcc-41fc-8e99-1a56ab9e1695"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79310"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4C30a_TptEe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c1d24d5-7740-4d6a-ae2f-f91e42db8598"
      },
      "source": [
        "#removing rows with cells that contain only non-alphabetic characters\n",
        "df=df[df['source_sentence'].str.contains('[A-Za-z]')]\n",
        "df=df[df['target_sentence'].str.contains('[A-Za-z]')]\n",
        "len(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76402"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AZIxSSSgpYc"
      },
      "source": [
        "# drop duplicate translations\n",
        "df_pp=df.copy()\n",
        "df_pp = df_pp.drop_duplicates()\n",
        "\n",
        "# drop conflicting translations\n",
        "df_pp.drop_duplicates(subset='source_sentence', inplace=True)\n",
        "df_pp.drop_duplicates(subset='target_sentence', inplace=True)\n",
        "\n",
        "# Shuffle the data to remove bias in dev set selection.\n",
        "df_pp = df_pp.sample(frac=1, random_state=seed).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDvhYjQDq0Sx"
      },
      "source": [
        "df_pp.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXEOvkCPq8ra",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "aa0f5aad-243a-42ac-e4b1-da2acc650a90"
      },
      "source": [
        "df_pp.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_sentence</th>\n",
              "      <th>target_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wanyuto nining ni wacwako yub ma dul pa Jehova...</td>\n",
              "      <td>How do we demonstrate our support for the arra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>( Niyabo 14 : 6 ) Lobo kibiloko doko Paradic ,...</td>\n",
              "      <td>Paradise will be restored on earth , and anyon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mitte ni waket tek wek wajal cawa me kwano Bai...</td>\n",
              "      <td>We need self - discipline to devote time to re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ma lubbe ki lok man , luot acel acel ma gitye ...</td>\n",
              "      <td>About this matter each Christian couple should...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nen kong gin mutimme i kom lakwena Paulo .</td>\n",
              "      <td>Consider what happened to the apostle Paul .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     source_sentence                                    target_sentence\n",
              "0  Wanyuto nining ni wacwako yub ma dul pa Jehova...  How do we demonstrate our support for the arra...\n",
              "1  ( Niyabo 14 : 6 ) Lobo kibiloko doko Paradic ,...  Paradise will be restored on earth , and anyon...\n",
              "2  Mitte ni waket tek wek wajal cawa me kwano Bai...  We need self - discipline to devote time to re...\n",
              "3  Ma lubbe ki lok man , luot acel acel ma gitye ...  About this matter each Christian couple should...\n",
              "4         Nen kong gin mutimme i kom lakwena Paulo .       Consider what happened to the apostle Paul ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l39IF7OoBxjF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "06503105-d3fd-4ccc-df73-294e6e6d14aa"
      },
      "source": [
        "df_pp.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_sentence</th>\n",
              "      <th>target_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wanyuto nining ni wacwako yub ma dul pa Jehova...</td>\n",
              "      <td>How do we demonstrate our support for the arra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>( Niyabo 14 : 6 ) Lobo kibiloko doko Paradic ,...</td>\n",
              "      <td>Paradise will be restored on earth , and anyon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mitte ni waket tek wek wajal cawa me kwano Bai...</td>\n",
              "      <td>We need self - discipline to devote time to re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ma lubbe ki lok man , luot acel acel ma gitye ...</td>\n",
              "      <td>About this matter each Christian couple should...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nen kong gin mutimme i kom lakwena Paulo .</td>\n",
              "      <td>Consider what happened to the apostle Paul .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     source_sentence                                    target_sentence\n",
              "0  Wanyuto nining ni wacwako yub ma dul pa Jehova...  How do we demonstrate our support for the arra...\n",
              "1  ( Niyabo 14 : 6 ) Lobo kibiloko doko Paradic ,...  Paradise will be restored on earth , and anyon...\n",
              "2  Mitte ni waket tek wek wajal cawa me kwano Bai...  We need self - discipline to devote time to re...\n",
              "3  Ma lubbe ki lok man , luot acel acel ma gitye ...  About this matter each Christian couple should...\n",
              "4         Nen kong gin mutimme i kom lakwena Paulo .       Consider what happened to the apostle Paul ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e5fER59X0eN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df8e36ef-1ca9-433e-e702-d1b9f33fc281"
      },
      "source": [
        "size=len(df_pp)\n",
        "size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73077"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8H6YyCCkIsn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0d41fbe-b4c8-41b5-ca2b-78656a91550d"
      },
      "source": [
        "# Split between train/dev/test- ratio 7:2:1 for then saves them as separate files\n",
        "import csv\n",
        "\n",
        "lc=True\n",
        "# Optional: lower case the corpora - this will make it easier to generalize, but without proper casing.\n",
        "if lc: \n",
        "    df_pp[\"source_sentence\"] = df_pp[\"source_sentence\"].str.lower()\n",
        "    df_pp[\"target_sentence\"] = df_pp[\"target_sentence\"].str.lower()\n",
        "\n",
        "train_size=int(size*0.7)\n",
        "train=df_pp.iloc[:train_size, 0:2]\n",
        "\n",
        "dev_size=int(size*0.2)\n",
        "end=train_size+dev_size\n",
        "dev=df_pp.iloc[train_size:end, 0:2]\n",
        "\n",
        "\n",
        "test_size=int(size*0.1)\n",
        "test=df_pp.iloc[end:, 0:2]\n",
        "\n",
        "\n",
        "with open(\"train.\"+source_language, \"w\") as src_file, open(\"train.\"+target_language, \"w\") as trg_file:\n",
        "  for index, row in train.iterrows():\n",
        "    src_file.write(row[\"source_sentence\"]+\"\\n\")\n",
        "    trg_file.write(row[\"target_sentence\"]+\"\\n\")\n",
        "    \n",
        "with open(\"dev.\"+source_language, \"w\") as src_file, open(\"dev.\"+target_language, \"w\") as trg_file:\n",
        "  for index, row in dev.iterrows():\n",
        "    src_file.write(row[\"source_sentence\"]+\"\\n\")\n",
        "    trg_file.write(row[\"target_sentence\"]+\"\\n\")\n",
        "\n",
        "with open(\"test.\"+source_language, \"w\") as src_file, open(\"test.\"+target_language, \"w\") as trg_file:\n",
        "  for index, row in test.iterrows():\n",
        "    src_file.write(row[\"source_sentence\"]+\"\\n\")\n",
        "    trg_file.write(row[\"target_sentence\"]+\"\\n\")\n",
        "\n",
        "df_pp.to_csv(\"ach-en\", header=False, index=False) \n",
        "\n",
        "\n",
        "# Doublecheck the format below. There should be no extra quotation marks or weird characters.\n",
        "! head train.*\n",
        "! head dev.*"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> train.ach <==\n",
            "wanyuto nining ni wacwako yub ma dul pa jehovah oketo ?\n",
            "( niyabo 14 : 6 ) lobo kibiloko doko paradic , dok ngat mo keken ma mito timo miti pa lubanga twero bedo iye !\n",
            "mitte ni waket tek wek wajal cawa me kwano baibul , kwan piwa kenwa , ki dong wot i cokkewa .\n",
            "ma lubbe ki lok man , luot acel acel ma gitye lukricitayo myero gumok tam pigi kengi ma weko cwinygi pe ngoligi kop .\n",
            "nen kong gin mutimme i kom lakwena paulo .\n",
            "* inge kare manok , en obolo catan kacel ki lumalaikane piny i lobo .\n",
            "ento lupwonye dini gunyweno pwony me baibul woko ; macalo adwogine , man oweko jo mapol gitamo ni pe giromo niang baibul wacel . ​ — tic pa lukwena 20 : 29 , 30 .\n",
            "baibul tye ki lanen pa jo ma gubedo luwaka ki ma gubedo lumwolo .\n",
            "( nen cal ma tye i pot karatac 17 . ) ( b ) ngo ma dong itimo wek lutinoni gubed agonya me lok kwedi ?\n",
            "calo kabaka solomon , leg bot jehovah wek omini ryeko me tiyo ticwa me pwony - nyi kacel ki ticci me kacokke .\n",
            "\n",
            "==> train.en <==\n",
            "how do we demonstrate our support for the arrangements made by jehovah’s organization ?\n",
            "paradise will be restored on earth , and anyone who wishes to do god’s will can be part of it !\n",
            "we need self - discipline to devote time to reading , study , and our christian meetings .\n",
            "about this matter each christian couple should make a decision that will allow them to have a good conscience .\n",
            "consider what happened to the apostle paul .\n",
            "* shortly afterward , he threw satan and his demons down to the earth .\n",
            "but teachers of religion have twisted bible teaching ; as a result , many people despair of ever understanding it . ​ — acts 20 : 29 , 30 .\n",
            "the bible contains examples of proud people as well as of humble people .\n",
            "( see opening image . ) ( b ) what have you done to make it easier for your children to talk to you ?\n",
            "like king solomon , pray to jehovah for wisdom in carrying out theocratic responsibilities .\n",
            "==> dev.ach <==\n",
            "en owacci : “ abedo kic kic kun bene akok .\n",
            "10 , 11 . ( a ) gin ango ma yecu owaco i carolokke i kom kal ki doo ?\n",
            "ento utmegiwa gitye ki twero kacel ki tic me moko tamgi pigi kengi .\n",
            "14 paradic i lobo ​ — lek mamwa kece lok ada ?\n",
            "( 2 temceo 3 : 1 ) nyo twero bedo ni jo ma wakwo kwedgi gitye ki cwiny marac , dok man twero turo cwinywa adada .\n",
            "lukricitayo mapol i kareni ginongo ni tek tutwal me niang kit ma lubanga wiro kwede ki jone .\n",
            "▪ lok mapol me ryeko ma yecu owacogi , tye ginonge i lok ma dano giloko nino ducu .\n",
            "lok pa yecu ma lubbe ki twon can madit atika - ni gudo jo pa jehovah nining ?\n",
            "( jon 5 : 16 , 17 ) en onongo tye ka waco gin ango ?\n",
            "( yakobo 1 : 17 ) mot ma pud dong anongo maber aye obedo nyoma ki dakona ma amaro adada , kristina .\n",
            "\n",
            "==> dev.en <==\n",
            "she says : “ i found myself lonely and weeping .\n",
            "10 , 11 . ( a ) what did jesus foretell in his parable of the wheat and the weeds ?\n",
            "still , our brothers and sisters have the right and the responsibility to make their own decisions .\n",
            "14 paradise on earth ​ — fantasy or reality ?\n",
            "or it could be that the wrong attitudes of people around us are causing us to feel tired and discouraged .\n",
            "the vast majority of god’s servants today may find this anointing process difficult to comprehend , and rightly so .\n",
            "many of jesus ’ wise sayings have , in various forms , entered everyday speech .\n",
            "what effect does jesus ’ prophecy about the great tribulation have on jehovah’s people ?\n",
            "what was the point ?\n",
            "a special blessing has been my marriage to my beloved wife , kristina .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZxE_HXCmzGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebd0c88f-6f38-48cd-b9cf-f1057bc24cd3"
      },
      "source": [
        "print((train_size,dev_size, test_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(51153, 14615, 7307)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrfPzzPfp8W9"
      },
      "source": [
        "# Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x1d6JuREF3T"
      },
      "source": [
        "device = 'cpu'\n",
        "if torch.cuda.is_available(): #check if GPU device is available\n",
        "    device = 'cuda' # assign the gpu to the device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "99454cde1ee74a458cd593323aaf7fe4",
            "7ce1a80f7d5e4cfd819ea5ec3dd1896d",
            "94b456ddca53435089bb30af2b6eb5ae",
            "ae9ee7781d0044bfb4e8691e3ee02cf2",
            "8b4dce032c374ce2a4501fb9d3377ed0",
            "77d58f9f091a41ab90ebfb972999e62c",
            "16d112a0d2e14f1b87a379c219c44545",
            "95ce872a07bb48f3bd79b9058a37694c",
            "25d1b72e561f4f6da6d9590ec6a7379a",
            "50766cfbb15043da9f7f0a47d3bee3c7",
            "9a52994d7e624ce99ceb5f36239d3876",
            "e4abcdd737e6489083631bfa1405edb7",
            "52a40e997bde4e3ba874c05d60c44163",
            "1c46b210e4524262adbdea7f4e7e9900",
            "040045e2a7e440e4814e5cb6a56dc357",
            "8fa6ca43c7044579b56273f78e369cbd",
            "9370d3c5529e4f28897a1f07de5b270d",
            "640b89333dd54218a35314ad45228ba6",
            "03edef6abf534e8e8e59b5319db8d350",
            "3b3ae8b58e154da290223b5d24989a2c",
            "9d8f963247a84ef2b90caa6fffe04523",
            "1c5c5dbe24194268bfa702963584220e",
            "552385d83c1e4e379e4e3fbc07146f34",
            "abddaefefea941aaba0e154e90111ad7",
            "8b169deffab94d9da3be24a5424d4710",
            "c49b46ebbd64411fa2e86ed2de280b64",
            "aa768c14e136423482b575e4d9a1e2ed",
            "830906cddbc94b98a6e29daf45f71cbd",
            "b390a1559657441fa3a610db1b37bedf",
            "44993f48629643a399c8760cd2b72ea9",
            "4929ceee0f3440db9333f50935b8de47",
            "a3dfd26daa7c41d3b81b86ca2b9e06f7",
            "433f1e436c5c469a948ddc83fc74ce82",
            "49cfab546c2f4f20a44f5c09966b196e",
            "afd1df97667f43b78dd75ccc538f8558",
            "f1f5bc8efc3e44cebf9a2c52e9bbdc91",
            "febbaca7cf504b8083ab99f3e5ab94ab",
            "9425a1a614b246f68e63478c8e78a4ef",
            "c783675a27ce40a09e504e94487a41e2",
            "a32ffb95156a486aa03b34ee1dd66c19"
          ]
        },
        "id": "4qjJKpiW0q84",
        "outputId": "991c5a59-2522-4001-d779-2670b79b2cb2"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-luo-en\")\r\n",
        "model = AutoModelWithLMHead.from_pretrained(\"Helsinki-NLP/opus-mt-luo-en\")  #Loading from hugging face models\r\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-luo-en\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99454cde1ee74a458cd593323aaf7fe4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1133.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25d1b72e561f4f6da6d9590ec6a7379a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=769849.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9370d3c5529e4f28897a1f07de5b270d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=741813.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b169deffab94d9da3be24a5424d4710",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1108211.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "433f1e436c5c469a948ddc83fc74ce82",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=43.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119,
          "referenced_widgets": [
            "23ac4abba34f4b1b89892354c4570c83",
            "7d9476d9f48c4d56be384ba2c1dcf2bd",
            "76d6e1944fb54941a23454611484a2ac",
            "ba978dbdbd89436ca0be9e6f30d9bb18",
            "0e9f77d038da4db182892a473748ac8b",
            "b6962e7a72ae400c81f9994a7c670eae",
            "0cfd512fd938467eb831558221afac2a",
            "f7f43c66403142a0a75d35927259b8fd"
          ]
        },
        "id": "_0hrAj2w06qb",
        "outputId": "49435082-fbe1-40c9-8728-5dd2a2b307aa"
      },
      "source": [
        "model = AutoModelWithLMHead.from_pretrained(\"Helsinki-NLP/opus-mt-luo-en\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/models/auto/modeling_auto.py:852: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23ac4abba34f4b1b89892354c4570c83",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=285893229.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JusycJQ41H7_",
        "outputId": "e56342db-80e1-4c05-dca9-fc642b5b119e"
      },
      "source": [
        "tokenizer.save_pretrained(\"./tokenizer\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./tokenizer/tokenizer_config.json',\n",
              " './tokenizer/special_tokens_map.json',\n",
              " PosixPath('tokenizer/source_spm'),\n",
              " PosixPath('tokenizer/target_spm'),\n",
              " PosixPath('tokenizer/vocab'),\n",
              " PosixPath('tokenizer/tokenizer_config_file'),\n",
              " './tokenizer/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVMlO4te3Vnq"
      },
      "source": [
        "!cp -R tokenizer './drive/My Drive/Year 4/Machine Learning/Loki/ach-en'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqqF5P4P4tBo"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZZXM4pm46Q1"
      },
      "source": [
        "##Model Fine Tuning the model\n",
        "Initially, we trained all the layers of the model. In this stage, I will freeze the encoder and just train the head layers of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ycpc3JjY4anI"
      },
      "source": [
        "#printing the paramaters of the base model- whether they are trainable or not- Initially they are all trainable\r\n",
        "for param in model.base_model.parameters():\r\n",
        "    print(param.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejLDqbEW999U",
        "outputId": "817f392a-d5c7-446c-8ef4-b1a3fa8b4917"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "   print(name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.shared.weight\n",
            "model.encoder.embed_positions.weight\n",
            "model.encoder.layers.0.self_attn.k_proj.weight\n",
            "model.encoder.layers.0.self_attn.k_proj.bias\n",
            "model.encoder.layers.0.self_attn.v_proj.weight\n",
            "model.encoder.layers.0.self_attn.v_proj.bias\n",
            "model.encoder.layers.0.self_attn.q_proj.weight\n",
            "model.encoder.layers.0.self_attn.q_proj.bias\n",
            "model.encoder.layers.0.self_attn.out_proj.weight\n",
            "model.encoder.layers.0.self_attn.out_proj.bias\n",
            "model.encoder.layers.0.self_attn_layer_norm.weight\n",
            "model.encoder.layers.0.self_attn_layer_norm.bias\n",
            "model.encoder.layers.0.fc1.weight\n",
            "model.encoder.layers.0.fc1.bias\n",
            "model.encoder.layers.0.fc2.weight\n",
            "model.encoder.layers.0.fc2.bias\n",
            "model.encoder.layers.0.final_layer_norm.weight\n",
            "model.encoder.layers.0.final_layer_norm.bias\n",
            "model.encoder.layers.1.self_attn.k_proj.weight\n",
            "model.encoder.layers.1.self_attn.k_proj.bias\n",
            "model.encoder.layers.1.self_attn.v_proj.weight\n",
            "model.encoder.layers.1.self_attn.v_proj.bias\n",
            "model.encoder.layers.1.self_attn.q_proj.weight\n",
            "model.encoder.layers.1.self_attn.q_proj.bias\n",
            "model.encoder.layers.1.self_attn.out_proj.weight\n",
            "model.encoder.layers.1.self_attn.out_proj.bias\n",
            "model.encoder.layers.1.self_attn_layer_norm.weight\n",
            "model.encoder.layers.1.self_attn_layer_norm.bias\n",
            "model.encoder.layers.1.fc1.weight\n",
            "model.encoder.layers.1.fc1.bias\n",
            "model.encoder.layers.1.fc2.weight\n",
            "model.encoder.layers.1.fc2.bias\n",
            "model.encoder.layers.1.final_layer_norm.weight\n",
            "model.encoder.layers.1.final_layer_norm.bias\n",
            "model.encoder.layers.2.self_attn.k_proj.weight\n",
            "model.encoder.layers.2.self_attn.k_proj.bias\n",
            "model.encoder.layers.2.self_attn.v_proj.weight\n",
            "model.encoder.layers.2.self_attn.v_proj.bias\n",
            "model.encoder.layers.2.self_attn.q_proj.weight\n",
            "model.encoder.layers.2.self_attn.q_proj.bias\n",
            "model.encoder.layers.2.self_attn.out_proj.weight\n",
            "model.encoder.layers.2.self_attn.out_proj.bias\n",
            "model.encoder.layers.2.self_attn_layer_norm.weight\n",
            "model.encoder.layers.2.self_attn_layer_norm.bias\n",
            "model.encoder.layers.2.fc1.weight\n",
            "model.encoder.layers.2.fc1.bias\n",
            "model.encoder.layers.2.fc2.weight\n",
            "model.encoder.layers.2.fc2.bias\n",
            "model.encoder.layers.2.final_layer_norm.weight\n",
            "model.encoder.layers.2.final_layer_norm.bias\n",
            "model.encoder.layers.3.self_attn.k_proj.weight\n",
            "model.encoder.layers.3.self_attn.k_proj.bias\n",
            "model.encoder.layers.3.self_attn.v_proj.weight\n",
            "model.encoder.layers.3.self_attn.v_proj.bias\n",
            "model.encoder.layers.3.self_attn.q_proj.weight\n",
            "model.encoder.layers.3.self_attn.q_proj.bias\n",
            "model.encoder.layers.3.self_attn.out_proj.weight\n",
            "model.encoder.layers.3.self_attn.out_proj.bias\n",
            "model.encoder.layers.3.self_attn_layer_norm.weight\n",
            "model.encoder.layers.3.self_attn_layer_norm.bias\n",
            "model.encoder.layers.3.fc1.weight\n",
            "model.encoder.layers.3.fc1.bias\n",
            "model.encoder.layers.3.fc2.weight\n",
            "model.encoder.layers.3.fc2.bias\n",
            "model.encoder.layers.3.final_layer_norm.weight\n",
            "model.encoder.layers.3.final_layer_norm.bias\n",
            "model.encoder.layers.4.self_attn.k_proj.weight\n",
            "model.encoder.layers.4.self_attn.k_proj.bias\n",
            "model.encoder.layers.4.self_attn.v_proj.weight\n",
            "model.encoder.layers.4.self_attn.v_proj.bias\n",
            "model.encoder.layers.4.self_attn.q_proj.weight\n",
            "model.encoder.layers.4.self_attn.q_proj.bias\n",
            "model.encoder.layers.4.self_attn.out_proj.weight\n",
            "model.encoder.layers.4.self_attn.out_proj.bias\n",
            "model.encoder.layers.4.self_attn_layer_norm.weight\n",
            "model.encoder.layers.4.self_attn_layer_norm.bias\n",
            "model.encoder.layers.4.fc1.weight\n",
            "model.encoder.layers.4.fc1.bias\n",
            "model.encoder.layers.4.fc2.weight\n",
            "model.encoder.layers.4.fc2.bias\n",
            "model.encoder.layers.4.final_layer_norm.weight\n",
            "model.encoder.layers.4.final_layer_norm.bias\n",
            "model.encoder.layers.5.self_attn.k_proj.weight\n",
            "model.encoder.layers.5.self_attn.k_proj.bias\n",
            "model.encoder.layers.5.self_attn.v_proj.weight\n",
            "model.encoder.layers.5.self_attn.v_proj.bias\n",
            "model.encoder.layers.5.self_attn.q_proj.weight\n",
            "model.encoder.layers.5.self_attn.q_proj.bias\n",
            "model.encoder.layers.5.self_attn.out_proj.weight\n",
            "model.encoder.layers.5.self_attn.out_proj.bias\n",
            "model.encoder.layers.5.self_attn_layer_norm.weight\n",
            "model.encoder.layers.5.self_attn_layer_norm.bias\n",
            "model.encoder.layers.5.fc1.weight\n",
            "model.encoder.layers.5.fc1.bias\n",
            "model.encoder.layers.5.fc2.weight\n",
            "model.encoder.layers.5.fc2.bias\n",
            "model.encoder.layers.5.final_layer_norm.weight\n",
            "model.encoder.layers.5.final_layer_norm.bias\n",
            "model.decoder.embed_positions.weight\n",
            "model.decoder.layers.0.self_attn.k_proj.weight\n",
            "model.decoder.layers.0.self_attn.k_proj.bias\n",
            "model.decoder.layers.0.self_attn.v_proj.weight\n",
            "model.decoder.layers.0.self_attn.v_proj.bias\n",
            "model.decoder.layers.0.self_attn.q_proj.weight\n",
            "model.decoder.layers.0.self_attn.q_proj.bias\n",
            "model.decoder.layers.0.self_attn.out_proj.weight\n",
            "model.decoder.layers.0.self_attn.out_proj.bias\n",
            "model.decoder.layers.0.self_attn_layer_norm.weight\n",
            "model.decoder.layers.0.self_attn_layer_norm.bias\n",
            "model.decoder.layers.0.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.0.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.0.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.0.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.0.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.0.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.0.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.0.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.0.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.0.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.0.fc1.weight\n",
            "model.decoder.layers.0.fc1.bias\n",
            "model.decoder.layers.0.fc2.weight\n",
            "model.decoder.layers.0.fc2.bias\n",
            "model.decoder.layers.0.final_layer_norm.weight\n",
            "model.decoder.layers.0.final_layer_norm.bias\n",
            "model.decoder.layers.1.self_attn.k_proj.weight\n",
            "model.decoder.layers.1.self_attn.k_proj.bias\n",
            "model.decoder.layers.1.self_attn.v_proj.weight\n",
            "model.decoder.layers.1.self_attn.v_proj.bias\n",
            "model.decoder.layers.1.self_attn.q_proj.weight\n",
            "model.decoder.layers.1.self_attn.q_proj.bias\n",
            "model.decoder.layers.1.self_attn.out_proj.weight\n",
            "model.decoder.layers.1.self_attn.out_proj.bias\n",
            "model.decoder.layers.1.self_attn_layer_norm.weight\n",
            "model.decoder.layers.1.self_attn_layer_norm.bias\n",
            "model.decoder.layers.1.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.1.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.1.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.1.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.1.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.1.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.1.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.1.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.1.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.1.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.1.fc1.weight\n",
            "model.decoder.layers.1.fc1.bias\n",
            "model.decoder.layers.1.fc2.weight\n",
            "model.decoder.layers.1.fc2.bias\n",
            "model.decoder.layers.1.final_layer_norm.weight\n",
            "model.decoder.layers.1.final_layer_norm.bias\n",
            "model.decoder.layers.2.self_attn.k_proj.weight\n",
            "model.decoder.layers.2.self_attn.k_proj.bias\n",
            "model.decoder.layers.2.self_attn.v_proj.weight\n",
            "model.decoder.layers.2.self_attn.v_proj.bias\n",
            "model.decoder.layers.2.self_attn.q_proj.weight\n",
            "model.decoder.layers.2.self_attn.q_proj.bias\n",
            "model.decoder.layers.2.self_attn.out_proj.weight\n",
            "model.decoder.layers.2.self_attn.out_proj.bias\n",
            "model.decoder.layers.2.self_attn_layer_norm.weight\n",
            "model.decoder.layers.2.self_attn_layer_norm.bias\n",
            "model.decoder.layers.2.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.2.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.2.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.2.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.2.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.2.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.2.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.2.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.2.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.2.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.2.fc1.weight\n",
            "model.decoder.layers.2.fc1.bias\n",
            "model.decoder.layers.2.fc2.weight\n",
            "model.decoder.layers.2.fc2.bias\n",
            "model.decoder.layers.2.final_layer_norm.weight\n",
            "model.decoder.layers.2.final_layer_norm.bias\n",
            "model.decoder.layers.3.self_attn.k_proj.weight\n",
            "model.decoder.layers.3.self_attn.k_proj.bias\n",
            "model.decoder.layers.3.self_attn.v_proj.weight\n",
            "model.decoder.layers.3.self_attn.v_proj.bias\n",
            "model.decoder.layers.3.self_attn.q_proj.weight\n",
            "model.decoder.layers.3.self_attn.q_proj.bias\n",
            "model.decoder.layers.3.self_attn.out_proj.weight\n",
            "model.decoder.layers.3.self_attn.out_proj.bias\n",
            "model.decoder.layers.3.self_attn_layer_norm.weight\n",
            "model.decoder.layers.3.self_attn_layer_norm.bias\n",
            "model.decoder.layers.3.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.3.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.3.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.3.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.3.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.3.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.3.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.3.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.3.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.3.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.3.fc1.weight\n",
            "model.decoder.layers.3.fc1.bias\n",
            "model.decoder.layers.3.fc2.weight\n",
            "model.decoder.layers.3.fc2.bias\n",
            "model.decoder.layers.3.final_layer_norm.weight\n",
            "model.decoder.layers.3.final_layer_norm.bias\n",
            "model.decoder.layers.4.self_attn.k_proj.weight\n",
            "model.decoder.layers.4.self_attn.k_proj.bias\n",
            "model.decoder.layers.4.self_attn.v_proj.weight\n",
            "model.decoder.layers.4.self_attn.v_proj.bias\n",
            "model.decoder.layers.4.self_attn.q_proj.weight\n",
            "model.decoder.layers.4.self_attn.q_proj.bias\n",
            "model.decoder.layers.4.self_attn.out_proj.weight\n",
            "model.decoder.layers.4.self_attn.out_proj.bias\n",
            "model.decoder.layers.4.self_attn_layer_norm.weight\n",
            "model.decoder.layers.4.self_attn_layer_norm.bias\n",
            "model.decoder.layers.4.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.4.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.4.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.4.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.4.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.4.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.4.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.4.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.4.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.4.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.4.fc1.weight\n",
            "model.decoder.layers.4.fc1.bias\n",
            "model.decoder.layers.4.fc2.weight\n",
            "model.decoder.layers.4.fc2.bias\n",
            "model.decoder.layers.4.final_layer_norm.weight\n",
            "model.decoder.layers.4.final_layer_norm.bias\n",
            "model.decoder.layers.5.self_attn.k_proj.weight\n",
            "model.decoder.layers.5.self_attn.k_proj.bias\n",
            "model.decoder.layers.5.self_attn.v_proj.weight\n",
            "model.decoder.layers.5.self_attn.v_proj.bias\n",
            "model.decoder.layers.5.self_attn.q_proj.weight\n",
            "model.decoder.layers.5.self_attn.q_proj.bias\n",
            "model.decoder.layers.5.self_attn.out_proj.weight\n",
            "model.decoder.layers.5.self_attn.out_proj.bias\n",
            "model.decoder.layers.5.self_attn_layer_norm.weight\n",
            "model.decoder.layers.5.self_attn_layer_norm.bias\n",
            "model.decoder.layers.5.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.5.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.5.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.5.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.5.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.5.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.5.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.5.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.5.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.5.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.5.fc1.weight\n",
            "model.decoder.layers.5.fc1.bias\n",
            "model.decoder.layers.5.fc2.weight\n",
            "model.decoder.layers.5.fc2.bias\n",
            "model.decoder.layers.5.final_layer_norm.weight\n",
            "model.decoder.layers.5.final_layer_norm.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTMjFLjY3F1b"
      },
      "source": [
        "#Freezing layers of the model\n",
        "\n",
        "#Option 1\n",
        "modules = [*model.get_encoder().layers[:4]] \n",
        "for module in modules:\n",
        "      param.requires_grad = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxKOuGUb9T0B",
        "outputId": "02b00924-c65f-4b5c-9bab-ed4b1d5072e6"
      },
      "source": [
        "#Option 2\n",
        "for name, param in model.base_model.named_parameters():\n",
        "        if name.startswith(\"encoder\"): #You can replace \"encoder\" with any layer you want to freeze\n",
        "            param.requires_grad = False\n",
        "            print(f\"Froze layer {name}...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Froze layer encoder.embed_positions.weight...\n",
            "Froze layer encoder.layers.0.self_attn.k_proj.weight...\n",
            "Froze layer encoder.layers.0.self_attn.k_proj.bias...\n",
            "Froze layer encoder.layers.0.self_attn.v_proj.weight...\n",
            "Froze layer encoder.layers.0.self_attn.v_proj.bias...\n",
            "Froze layer encoder.layers.0.self_attn.q_proj.weight...\n",
            "Froze layer encoder.layers.0.self_attn.q_proj.bias...\n",
            "Froze layer encoder.layers.0.self_attn.out_proj.weight...\n",
            "Froze layer encoder.layers.0.self_attn.out_proj.bias...\n",
            "Froze layer encoder.layers.0.self_attn_layer_norm.weight...\n",
            "Froze layer encoder.layers.0.self_attn_layer_norm.bias...\n",
            "Froze layer encoder.layers.0.fc1.weight...\n",
            "Froze layer encoder.layers.0.fc1.bias...\n",
            "Froze layer encoder.layers.0.fc2.weight...\n",
            "Froze layer encoder.layers.0.fc2.bias...\n",
            "Froze layer encoder.layers.0.final_layer_norm.weight...\n",
            "Froze layer encoder.layers.0.final_layer_norm.bias...\n",
            "Froze layer encoder.layers.1.self_attn.k_proj.weight...\n",
            "Froze layer encoder.layers.1.self_attn.k_proj.bias...\n",
            "Froze layer encoder.layers.1.self_attn.v_proj.weight...\n",
            "Froze layer encoder.layers.1.self_attn.v_proj.bias...\n",
            "Froze layer encoder.layers.1.self_attn.q_proj.weight...\n",
            "Froze layer encoder.layers.1.self_attn.q_proj.bias...\n",
            "Froze layer encoder.layers.1.self_attn.out_proj.weight...\n",
            "Froze layer encoder.layers.1.self_attn.out_proj.bias...\n",
            "Froze layer encoder.layers.1.self_attn_layer_norm.weight...\n",
            "Froze layer encoder.layers.1.self_attn_layer_norm.bias...\n",
            "Froze layer encoder.layers.1.fc1.weight...\n",
            "Froze layer encoder.layers.1.fc1.bias...\n",
            "Froze layer encoder.layers.1.fc2.weight...\n",
            "Froze layer encoder.layers.1.fc2.bias...\n",
            "Froze layer encoder.layers.1.final_layer_norm.weight...\n",
            "Froze layer encoder.layers.1.final_layer_norm.bias...\n",
            "Froze layer encoder.layers.2.self_attn.k_proj.weight...\n",
            "Froze layer encoder.layers.2.self_attn.k_proj.bias...\n",
            "Froze layer encoder.layers.2.self_attn.v_proj.weight...\n",
            "Froze layer encoder.layers.2.self_attn.v_proj.bias...\n",
            "Froze layer encoder.layers.2.self_attn.q_proj.weight...\n",
            "Froze layer encoder.layers.2.self_attn.q_proj.bias...\n",
            "Froze layer encoder.layers.2.self_attn.out_proj.weight...\n",
            "Froze layer encoder.layers.2.self_attn.out_proj.bias...\n",
            "Froze layer encoder.layers.2.self_attn_layer_norm.weight...\n",
            "Froze layer encoder.layers.2.self_attn_layer_norm.bias...\n",
            "Froze layer encoder.layers.2.fc1.weight...\n",
            "Froze layer encoder.layers.2.fc1.bias...\n",
            "Froze layer encoder.layers.2.fc2.weight...\n",
            "Froze layer encoder.layers.2.fc2.bias...\n",
            "Froze layer encoder.layers.2.final_layer_norm.weight...\n",
            "Froze layer encoder.layers.2.final_layer_norm.bias...\n",
            "Froze layer encoder.layers.3.self_attn.k_proj.weight...\n",
            "Froze layer encoder.layers.3.self_attn.k_proj.bias...\n",
            "Froze layer encoder.layers.3.self_attn.v_proj.weight...\n",
            "Froze layer encoder.layers.3.self_attn.v_proj.bias...\n",
            "Froze layer encoder.layers.3.self_attn.q_proj.weight...\n",
            "Froze layer encoder.layers.3.self_attn.q_proj.bias...\n",
            "Froze layer encoder.layers.3.self_attn.out_proj.weight...\n",
            "Froze layer encoder.layers.3.self_attn.out_proj.bias...\n",
            "Froze layer encoder.layers.3.self_attn_layer_norm.weight...\n",
            "Froze layer encoder.layers.3.self_attn_layer_norm.bias...\n",
            "Froze layer encoder.layers.3.fc1.weight...\n",
            "Froze layer encoder.layers.3.fc1.bias...\n",
            "Froze layer encoder.layers.3.fc2.weight...\n",
            "Froze layer encoder.layers.3.fc2.bias...\n",
            "Froze layer encoder.layers.3.final_layer_norm.weight...\n",
            "Froze layer encoder.layers.3.final_layer_norm.bias...\n",
            "Froze layer encoder.layers.4.self_attn.k_proj.weight...\n",
            "Froze layer encoder.layers.4.self_attn.k_proj.bias...\n",
            "Froze layer encoder.layers.4.self_attn.v_proj.weight...\n",
            "Froze layer encoder.layers.4.self_attn.v_proj.bias...\n",
            "Froze layer encoder.layers.4.self_attn.q_proj.weight...\n",
            "Froze layer encoder.layers.4.self_attn.q_proj.bias...\n",
            "Froze layer encoder.layers.4.self_attn.out_proj.weight...\n",
            "Froze layer encoder.layers.4.self_attn.out_proj.bias...\n",
            "Froze layer encoder.layers.4.self_attn_layer_norm.weight...\n",
            "Froze layer encoder.layers.4.self_attn_layer_norm.bias...\n",
            "Froze layer encoder.layers.4.fc1.weight...\n",
            "Froze layer encoder.layers.4.fc1.bias...\n",
            "Froze layer encoder.layers.4.fc2.weight...\n",
            "Froze layer encoder.layers.4.fc2.bias...\n",
            "Froze layer encoder.layers.4.final_layer_norm.weight...\n",
            "Froze layer encoder.layers.4.final_layer_norm.bias...\n",
            "Froze layer encoder.layers.5.self_attn.k_proj.weight...\n",
            "Froze layer encoder.layers.5.self_attn.k_proj.bias...\n",
            "Froze layer encoder.layers.5.self_attn.v_proj.weight...\n",
            "Froze layer encoder.layers.5.self_attn.v_proj.bias...\n",
            "Froze layer encoder.layers.5.self_attn.q_proj.weight...\n",
            "Froze layer encoder.layers.5.self_attn.q_proj.bias...\n",
            "Froze layer encoder.layers.5.self_attn.out_proj.weight...\n",
            "Froze layer encoder.layers.5.self_attn.out_proj.bias...\n",
            "Froze layer encoder.layers.5.self_attn_layer_norm.weight...\n",
            "Froze layer encoder.layers.5.self_attn_layer_norm.bias...\n",
            "Froze layer encoder.layers.5.fc1.weight...\n",
            "Froze layer encoder.layers.5.fc1.bias...\n",
            "Froze layer encoder.layers.5.fc2.weight...\n",
            "Froze layer encoder.layers.5.fc2.bias...\n",
            "Froze layer encoder.layers.5.final_layer_norm.weight...\n",
            "Froze layer encoder.layers.5.final_layer_norm.bias...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUrGPCRfu5c8"
      },
      "source": [
        "#Option 3\n",
        "from torch import nn\n",
        "from typing import Callable, Dict, Iterable, List, Tuple, Union\n",
        "\n",
        "\n",
        "def freeze_params(model: nn.Module):\n",
        "    \"\"\"Set requires_grad=False for each of model.parameters()\"\"\"\n",
        "    for par in model.parameters():\n",
        "        par.requires_grad = False\n",
        "\n",
        "def freeze_embeds(model):\n",
        "    \"\"\"Freeze token embeddings and positional embeddings for bart, just token embeddings for t5.\"\"\"\n",
        "    model_type = model.config.model_type\n",
        "\n",
        "    if model_type == \"t5\":\n",
        "        freeze_params(model.shared)\n",
        "        for d in [model.encoder, model.decoder]:\n",
        "            freeze_params(d.embed_tokens)\n",
        "    elif model_type == \"fsmt\":\n",
        "        for d in [model.model.encoder, model.model.decoder]:\n",
        "            freeze_params(d.embed_positions)\n",
        "            freeze_params(d.embed_tokens)\n",
        "    else:\n",
        "        freeze_params(model.model.shared)\n",
        "        for d in [model.model.encoder, model.model.decoder]:\n",
        "            freeze_params(d.embed_positions)\n",
        "            freeze_params(d.embed_tokens)\n",
        "\n",
        "\n",
        "def grad_status(model: nn.Module) -> Iterable:\n",
        "    return (par.requires_grad for par in model.parameters())\n",
        "\n",
        "\n",
        "def any_requires_grad(model: nn.Module) -> bool:\n",
        "    return any(grad_status(model))\n",
        "\n",
        "\n",
        "def assert_all_frozen(model):\n",
        "    model_grads: List[bool] = list(grad_status(model))\n",
        "    n_require_grad = sum(lmap(int, model_grads))\n",
        "    npars = len(model_grads)\n",
        "    assert not any(model_grads), f\"{n_require_grad/npars:.1%} of {npars} weights require grad\"\n",
        "\n",
        "\n",
        "def assert_not_all_frozen(model):\n",
        "    model_grads: List[bool] = list(grad_status(model))\n",
        "    npars = len(model_grads)\n",
        "    assert any(model_grads), f\"none of {npars} weights require grad\"\n",
        "\n",
        "def lmap(f: Callable, x: Iterable) -> List:\n",
        "    \"\"\"list(map(f, x))\"\"\"\n",
        "    return list(map(f, x))\n",
        "\n",
        "#*******FREEZE SECTION *********\n",
        "freeze_params(model.get_encoder())\n",
        "assert_all_frozen(model.get_encoder())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ0Nu8-9veKE"
      },
      "source": [
        "###Transfer the model to GPU, or CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10BpOLEDEcAF"
      },
      "source": [
        "model = model.to(device) # bind the model to the GPU device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz46jRjiqtmw"
      },
      "source": [
        "##Testing the model before retraining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9qFxChQExLn"
      },
      "source": [
        "src_texts = [ \"Gitye ki cwiny calo pa lanebi Icaya\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMXSeNvNGoaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbec8044-590f-4896-d3ed-3e9f94b58dab"
      },
      "source": [
        "tokens=tokenizer.prepare_seq2seq_batch(src_texts)\n",
        "tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 1701,  6137,    49,  2944,  8134, 39413,  8134, 13849,  4822,  6919,\n",
              "           181, 17142,    47,  2837, 17140,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E49ICDmLH-v3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed93950a-83be-497b-82a7-aac26ac0423d"
      },
      "source": [
        "type(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.tokenization_utils_base.BatchEncoding"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngRkvSbqH9kR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "502c917b-a9a3-4962-d1a3-07ffe9cc6397"
      },
      "source": [
        "tokens.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 1701,  6137,    49,  2944,  8134, 39413,  8134, 13849,  4822,  6919,\n",
              "           181, 17142,    47,  2837, 17140,     0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAaAL-0CF-QD"
      },
      "source": [
        "translated = model.generate(**tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ggWByHQLtC5"
      },
      "source": [
        "tgt_text = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUi1sI59LyR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a16b2a9d-02f4-4c5d-ad7c-e2c7d0b3bb88"
      },
      "source": [
        "tgt_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['they are like the prophet isaiah']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbCOL2Pr-i1S"
      },
      "source": [
        "test_predictions=[]\n",
        "\n",
        "def test_model(model,tokenizer, test_df):\n",
        "\n",
        "  for row in test_df[\"source_sentence\"]:\n",
        "    tokens=tokenizer.prepare_seq2seq_batch([row])\n",
        "    tokens.to(device)\n",
        "    translated = model.generate(**tokens)\n",
        "    tgt_text = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
        "    test_predictions.append(tgt_text[0])\n",
        "\n",
        "  reference_preds=pd.DataFrame({\"Predictions\": test_predictions, \"Reference\": test[\"target_sentence\"]})\n",
        "\n",
        "  return reference_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMVeP3CQ-8sw"
      },
      "source": [
        "def gen_bleu_score(pred_ref_df):\n",
        "  from nltk.translate.bleu_score import corpus_bleu\n",
        "  ref_tokens=[]\n",
        "  pred_tokens=[]\n",
        "\n",
        "  for row in pred_ref_df[\"Reference\"]:\n",
        "    ref_tokens.append(row.split())\n",
        "  for row in pred_ref_df[\"Predictions\"]:\n",
        "   pred_tokens.append(row.split())\n",
        "\n",
        "   return corpus_bleu(ref_tokens, pred_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAllEvSdwFwT"
      },
      "source": [
        "pred_ref_df=test_model(model, tokenizer, test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ13ahekSRqd"
      },
      "source": [
        "test.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-8VjBCYL6wI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "4e2d95af-2bd4-45d6-e202-7199fc869fb1"
      },
      "source": [
        "pred_ref_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predictions</th>\n",
              "      <th>Reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>65768</th>\n",
              "      <td>A relatively short smile, a white horse, quick...</td>\n",
              "      <td>yes , we can because the very act of creation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65769</th>\n",
              "      <td>He was also aware of the fact that if he is to...</td>\n",
              "      <td>he also knew that his disciples would need cou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65770</th>\n",
              "      <td>I'm told you that they have been locked down a...</td>\n",
              "      <td>thanks to the explanations in the christian gr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65771</th>\n",
              "      <td>He is a lender, and he sees the oil that it is...</td>\n",
              "      <td>but jehovah saw a potential for good in us .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65772</th>\n",
              "      <td>To illustrate: \"I've found it easier to turn b...</td>\n",
              "      <td>titus related that the brothers in corinth had...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Predictions                                          Reference\n",
              "65768  A relatively short smile, a white horse, quick...  yes , we can because the very act of creation ...\n",
              "65769  He was also aware of the fact that if he is to...  he also knew that his disciples would need cou...\n",
              "65770  I'm told you that they have been locked down a...  thanks to the explanations in the christian gr...\n",
              "65771  He is a lender, and he sees the oil that it is...       but jehovah saw a potential for good in us .\n",
              "65772  To illustrate: \"I've found it easier to turn b...  titus related that the brothers in corinth had..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XK7v4KvXseK"
      },
      "source": [
        "pred_ref_df.to_csv(\"initial pred.csv\",header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqv5uXp-b5pN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9c0b4d4-1d3c-4e55-d242-6bd107defe2d"
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "ref_tokens=[]\n",
        "pred_tokens=[]\n",
        "\n",
        "for row in pred_ref_df[\"Reference\"]:\n",
        "    ref_tokens.append(row.split())\n",
        "for row in pred_ref_df[\"Predictions\"]:\n",
        "   pred_tokens.append(row.split())\n",
        "\n",
        "corpus_bleu(ref_tokens, pred_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.019551158342908225"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ5kkI45dF0V"
      },
      "source": [
        "##Transforming training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WnrBpPIZGaF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb2496e2-897c-408a-c6af-10835d88fa74"
      },
      "source": [
        "train_tokens=tokenizer.prepare_seq2seq_batch(list(train[\"source_sentence\"]), tgt_texts=list(train[\"target_sentence\"]), padding=True,truncation=True, return_tensors=\"pt\" )\n",
        "train_tokens.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[44148, 49453,    16,  ..., 52235, 52235, 52235],\n",
              "        [   39,     1,   192,  ..., 52235, 52235, 52235],\n",
              "        [  248, 26168,    16,  ..., 52235, 52235, 52235],\n",
              "        ...,\n",
              "        [   39, 21847,    44,  ..., 52235, 52235, 52235],\n",
              "        [ 1474,    28,  6609,  ..., 52235, 52235, 52235],\n",
              "        [   39, 13422,   453,  ..., 52235, 52235, 52235]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'labels': tensor([[  166,    93,    34,  ..., 52235, 52235, 52235],\n",
              "        [ 2381,    52,    42,  ..., 52235, 52235, 52235],\n",
              "        [   34,   250,  1196,  ..., 52235, 52235, 52235],\n",
              "        ...,\n",
              "        [  411,    54,     5,  ..., 52235, 52235, 52235],\n",
              "        [   18,   182,  2678,  ..., 52235, 52235, 52235],\n",
              "        [   79,    22,   150,  ..., 52235, 52235, 52235]], device='cuda:0')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UOu5RMxXCrJ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euTLnImrc2eH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ee16050-d0a8-4c2e-f7e9-fcfb6fe74293"
      },
      "source": [
        "dev_tokens=tokenizer.prepare_seq2seq_batch(list(dev[\"source_sentence\"]), tgt_texts=list(dev[\"target_sentence\"]), padding=True,truncation=True, return_tensors=\"pt\" )\n",
        "dev_tokens.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[   32,    44,  5586,  ..., 52235, 52235, 52235],\n",
              "        [  277,    44,     3,  ..., 52235, 52235, 52235],\n",
              "        [   32,  1925,  4786,  ..., 52235, 52235, 52235],\n",
              "        ...,\n",
              "        [ 6919,  7492,  7601,  ..., 52235, 52235, 52235],\n",
              "        [  111, 47451,    13,  ..., 52235, 52235, 52235],\n",
              "        [ 8134, 39370,   286,  ..., 52235, 52235, 52235]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'labels': tensor([[  276,   342,    44,  ..., 52235, 52235, 52235],\n",
              "        [  277,    44,     3,  ..., 52235, 52235, 52235],\n",
              "        [  765,    44,     3,  ..., 52235, 52235, 52235],\n",
              "        ...,\n",
              "        [    5,  3381,   639,  ..., 52235, 52235, 52235],\n",
              "        [    5,  1273,    29,  ..., 52235, 52235, 52235],\n",
              "        [ 5620,   799,   158,  ..., 52235, 52235, 52235]], device='cuda:0')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEYwgtr9EwS1"
      },
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, data, maxlen, tokenizer, with_labels=True,):\n",
        "\n",
        "        self.data = data  # pandas dataframe\n",
        "        #Initialize the tokenizer\n",
        "        self.tokenizer = tokenizer  \n",
        "\n",
        "        # self.tokenized_data = self.tokenizer\n",
        "\n",
        "        self.maxlen = maxlen\n",
        "        self.with_labels = with_labels \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # print(type(self.data))\n",
        "        # print(\"index:\", index)\n",
        "\n",
        "        # Selecting sentence1 and sentence2 at the specified index in the data frame\n",
        "        sent1 = [self.data.loc[index, \"source_sentence\"]]\n",
        "        sent2 = [self.data.loc[index, \"target_sentence\"]]\n",
        "\n",
        "        # print(\"Sent1:\", len(sent1))\n",
        "        # print(sent1)\n",
        "        # print(\"Sent2:\", len(sent2))\n",
        "        # print(sent2)\n",
        "\n",
        "        # Tokenize the pair of sentences to get token ids, attention masks and token type ids\n",
        "        encoded_pair = self.tokenizer.prepare_seq2seq_batch(sent1, sent2, \n",
        "                                      # max_length=tokenizer.max_len,\n",
        "                                      padding='max_length',  # Pad to max_length\n",
        "                                      truncation=True,  # Truncate to max_length\n",
        "                                      return_tensors='pt')  # Return torch.Tensor objects\n",
        "\n",
        "         \n",
        "        # for key in encoded_pair.keys():\n",
        "          # print(\"encoded pair : %s : %s\"%(key, str(encoded_pair[key].size())))\n",
        "          # print(encoded_pair[key])\n",
        "          # print(tokenizer.convert_ids_to_tokens(encoded_pair[key].squeeze(0)))\n",
        "\n",
        "        encoded_pair['input_ids'] = encoded_pair['input_ids'].squeeze(0)  # tensor of token ids\n",
        "        encoded_pair['attention_mask'] = encoded_pair['attention_mask'].squeeze(0)  # binary tensor with \"0\" for padded values and \"1\" for the other values\n",
        "\n",
        "        # print(\"ids:\", input_ids.size())\n",
        "        # print(attn_masks.size())\n",
        "\n",
        "        if self.with_labels:  # True if the dataset has labels\n",
        "            encoded_pair['labels'] = encoded_pair['labels'].squeeze(0)\n",
        "            # return input_ids, attn_masks, label   -- This is what I saw in an example. It resulted to an erroe\n",
        "            return encoded_pair\n",
        "            # return sent1, sent2\n",
        "        else:\n",
        "            # return sent1, sent2\n",
        "            return input_ids, attn_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw_O8LXC2ELj"
      },
      "source": [
        "dev.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJbvhLOe-U5h"
      },
      "source": [
        "train_dataset= CustomDataset(train, 1024, tokenizer, with_labels=True,)\n",
        "eval_dataset= CustomDataset(dev, 1024, tokenizer, with_labels=True,)\n",
        "\n",
        "# batch_size = 1\n",
        "\n",
        "# train_loader= DataLoader(train,shuffle=False,batch_size=batch_size,)\n",
        "# valid_loader =DataLoader(valid,shuffle=False,batch_size=batch_size,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Em8bDjodHxt"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VahUvtBZd--V"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total # of training epochs\n",
        "    per_device_train_batch_size=4,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    #tokenizer=tokenizer\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d61ad1hcHq2l"
      },
      "source": [
        "trainer.train()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BidlCJ7LJkRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f29e5db-c910-4c32-98b0-fca9e3882a0b"
      },
      "source": [
        "test_tokens=tokenizer.prepare_seq2seq_batch(list(test[\"source_sentence\"]),padding=True,truncation=True, return_tensors=\"pt\" )\n",
        "test_tokens.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[13819, 12963,    44,  ..., 52235, 52235, 52235],\n",
              "        [   32,    42,   181,  ..., 52235, 52235, 52235],\n",
              "        [ 8134, 39413,   293,  ..., 52235, 52235, 52235],\n",
              "        ...,\n",
              "        [   32,  2157,  6867,  ..., 52235, 52235, 52235],\n",
              "        [ 3211,    16,  2824,  ..., 52235, 52235, 52235],\n",
              "        [   28, 32022,  7219,  ..., 52235, 52235, 52235]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdN8Xe0kdf0d"
      },
      "source": [
        "##Model Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AySQ9aESUpTe"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D9qx73Pv4K9"
      },
      "source": [
        "test_predictions\n",
        "\n",
        "#Option 1:#Gives CUDA Runtime Error -Out of memory\n",
        "#test_predictions = [tokenizer.decode(t, skip_special_tokens=True) for t in model.generate(**test_tokens)]\n",
        "\n",
        "#option2\n",
        "ref_preds_final=test_model(model,tokenizer,test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCQr42TKKLNu"
      },
      "source": [
        "#ref_preds_final=pd.DataFrame({\"Predictions\": test_predictions, \"Reference\": test[\"target_sentence\"]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXpVDKX5LZMs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "0c0b4a8f-5ecf-49c5-80fa-e6ab23273d8e"
      },
      "source": [
        "ref_preds_final.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predictions</th>\n",
              "      <th>Reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>65768</th>\n",
              "      <td>we can be sure, for as god created humans with...</td>\n",
              "      <td>yes , we can because the very act of creation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65769</th>\n",
              "      <td>he also knew that he needed to encourage his d...</td>\n",
              "      <td>he also knew that his disciples would need cou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65770</th>\n",
              "      <td>thankfully, the greek scriptures assure us tha...</td>\n",
              "      <td>thanks to the explanations in the christian gr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65771</th>\n",
              "      <td>but jehovah saw something good in our lives.</td>\n",
              "      <td>but jehovah saw a potential for good in us .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65772</th>\n",
              "      <td>it explains that the brothers in corinth appli...</td>\n",
              "      <td>titus related that the brothers in corinth had...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65773</th>\n",
              "      <td>how can we be sure that a person is not guided...</td>\n",
              "      <td>how can we identify a physical person ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65774</th>\n",
              "      <td>( read psalm 119 : 130 ; john 16 : 13. )</td>\n",
              "      <td>( read psalm 119 : 130 ; john 16 : 13 . )</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65775</th>\n",
              "      <td>he left behind and lost gods favor and his fav...</td>\n",
              "      <td>he went astray and lost the favor of our patie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65776</th>\n",
              "      <td>the apostle paul explained this when he said :...</td>\n",
              "      <td>the apostle paul was being realistic when he w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65777</th>\n",
              "      <td>he was very angry with his heart.</td>\n",
              "      <td>queen esther was greatly distressed .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65778</th>\n",
              "      <td>for guidance, ask a trusted friend about the w...</td>\n",
              "      <td>for guidance , you turn to a trusted friend wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65779</th>\n",
              "      <td>this will give them the opportunity to help th...</td>\n",
              "      <td>then we would be in a position to act appropri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65780</th>\n",
              "      <td>parents can work hard to help their children c...</td>\n",
              "      <td>parents can do much to help their children see...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65781</th>\n",
              "      <td>when you preach in public and in your literatu...</td>\n",
              "      <td>when you are doing public witnessing using a l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65782</th>\n",
              "      <td>it gives us opportunities to show our love for...</td>\n",
              "      <td>they give us opportunities to show our brother...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65783</th>\n",
              "      <td>but how did paul view it as a privilege to be ...</td>\n",
              "      <td>but how did paul view this when compared with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65784</th>\n",
              "      <td>when jesus was resurrected, he appeared to peo...</td>\n",
              "      <td>the resurrected jesus appeared to individuals ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65785</th>\n",
              "      <td>if our faith is based on accurate knowledge, w...</td>\n",
              "      <td>if our faith is built on accurate knowledge , ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65786</th>\n",
              "      <td>18 draw close to god</td>\n",
              "      <td>16 learn from god’s word ​ — when did jesus be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65787</th>\n",
              "      <td>but he felt compassion, for that day i did not...</td>\n",
              "      <td>nevertheless , i was shown mercy because i act...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Predictions                                          Reference\n",
              "65768  we can be sure, for as god created humans with...  yes , we can because the very act of creation ...\n",
              "65769  he also knew that he needed to encourage his d...  he also knew that his disciples would need cou...\n",
              "65770  thankfully, the greek scriptures assure us tha...  thanks to the explanations in the christian gr...\n",
              "65771       but jehovah saw something good in our lives.       but jehovah saw a potential for good in us .\n",
              "65772  it explains that the brothers in corinth appli...  titus related that the brothers in corinth had...\n",
              "65773  how can we be sure that a person is not guided...            how can we identify a physical person ?\n",
              "65774           ( read psalm 119 : 130 ; john 16 : 13. )          ( read psalm 119 : 130 ; john 16 : 13 . )\n",
              "65775  he left behind and lost gods favor and his fav...  he went astray and lost the favor of our patie...\n",
              "65776  the apostle paul explained this when he said :...  the apostle paul was being realistic when he w...\n",
              "65777                 he was very angry with his heart.               queen esther was greatly distressed .\n",
              "65778  for guidance, ask a trusted friend about the w...  for guidance , you turn to a trusted friend wh...\n",
              "65779  this will give them the opportunity to help th...  then we would be in a position to act appropri...\n",
              "65780  parents can work hard to help their children c...  parents can do much to help their children see...\n",
              "65781  when you preach in public and in your literatu...  when you are doing public witnessing using a l...\n",
              "65782  it gives us opportunities to show our love for...  they give us opportunities to show our brother...\n",
              "65783  but how did paul view it as a privilege to be ...  but how did paul view this when compared with ...\n",
              "65784  when jesus was resurrected, he appeared to peo...  the resurrected jesus appeared to individuals ...\n",
              "65785  if our faith is based on accurate knowledge, w...  if our faith is built on accurate knowledge , ...\n",
              "65786                              18 draw close to god   16 learn from god’s word ​ — when did jesus be...\n",
              "65787  but he felt compassion, for that day i did not...  nevertheless , i was shown mercy because i act..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgSZWmnxBnpP"
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUACSJkWZ3lm"
      },
      "source": [
        "ref_preds_final.to_csv(\"ach-en-pred-ref-v2.csv\",header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXSjE5zsJVwo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8076b401-be34-4ae3-e642-5758edce40b8"
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "ref_tokens=[]\n",
        "pred_tokens=[]\n",
        "\n",
        "for row in pred_ref_df[\"Reference\"]:\n",
        "    ref_tokens.append(row.split())\n",
        "for row in pred_ref_df[\"Predictions\"]:\n",
        "   pred_tokens.append(row.split())\n",
        "\n",
        "corpus_bleu(ref_tokens, pred_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4615432484914063"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwHxeiOvxgQ4"
      },
      "source": [
        "###Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLP7U_xuxX1d"
      },
      "source": [
        "model.save(\"./model\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}